{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0731ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg\n",
    "from typing import Literal\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    ToolMessage,\n",
    "    SystemMessage,\n",
    "    RemoveMessage,\n",
    ")\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\n",
    "\n",
    "# Optional: visualisation\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a69cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b541b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_uri = \"postgresql://devuser:changeme@localhost:5433/devdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8cdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82737939",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0)\n",
    "db = SQLDatabase.from_uri(db_uri)\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "get_schema_tool = next(t for t in tools if t.name == \"sql_db_schema\")\n",
    "run_query_tool = next(t for t in tools if t.name == \"sql_db_query\")\n",
    "list_tables_tool = next(t for t in tools if t.name == \"sql_db_list_tables\")\n",
    "\n",
    "get_schema_node = ToolNode([get_schema_tool])\n",
    "run_query_node = ToolNode([run_query_tool])\n",
    "list_tables_node = ToolNode([list_tables_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90cbb36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f04877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Node: fabricate a tool call for list_tables and let ToolNode run it ---\n",
    "def prep_list_tables(state: State):\n",
    "    call_id = \"list_tables-1\"\n",
    "    # Return an AI message that *requests* the tool; ToolNode will execute it next\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=\"\",\n",
    "                tool_calls=[{\"name\": \"sql_db_list_tables\", \"args\": {}, \"id\": call_id}],\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Optional: format the list tables result into a friendly AI message\n",
    "def show_tables(state: State):\n",
    "    # The last message should be the ToolMessage from the ToolNode\n",
    "    tm = state[\"messages\"][-1]\n",
    "    if isinstance(tm, ToolMessage):\n",
    "        return {\"messages\": [AIMessage(content=f\"Available tables: {tm.content}\")]}\n",
    "    return {}\n",
    "\n",
    "# --- Node: call get_schema via the model (the ToolNode will execute it) ---\n",
    "def call_get_schema(state: State):\n",
    "    llm_with_tools = llm.bind_tools([get_schema_tool], tool_choice=\"any\")\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# --- Node: generate SQL (may or may not call the run_query tool) ---\n",
    "generate_query_system_prompt = (\n",
    "    \"You are an agent designed to interact with a SQL database.\\n\"\n",
    "    f\"Given an input question, create a syntactically correct {db.dialect} query to run,\\n\"\n",
    "    \"then look at the results of the query and return the answer. Unless the user\\n\"\n",
    "    \"specifies a specific number of examples they wish to obtain, always limit your\\n\"\n",
    "    \"query to at most 5 results.\\n\\n\"\n",
    "    \"You can order the results by a relevant column to return the most interesting examples.\\n\"\n",
    "    \"Never SELECT *; only ask for relevant columns. Do not perform DML.\\n\"\n",
    ")\n",
    "\n",
    "def generate_query(state: State):\n",
    "    llm_with_tools = llm.bind_tools([run_query_tool])  # let model decide to call or not\n",
    "    msgs = [SystemMessage(content=generate_query_system_prompt), *state[\"messages\"]]\n",
    "    response = llm_with_tools.invoke(msgs)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# --- Node: optionally rewrite/validate SQL before execution ---\n",
    "check_query_system_prompt = (\n",
    "    \"You are a SQL expert. Double-check the query for:\\n\"\n",
    "    \"- NOT IN with NULLs\\n- UNION vs UNION ALL\\n- BETWEEN exclusivity\\n\"\n",
    "    \"- Type mismatches\\n- Quoted identifiers\\n- Function arg counts\\n\"\n",
    "    \"- Correct casting\\n- Proper join keys\\n\\n\"\n",
    "    \"If issues exist, rewrite the query; otherwise return the original.\\n\"\n",
    "    \"Then call the execution tool.\"\n",
    ")\n",
    "\n",
    "def check_query(state: State):\n",
    "    last = state[\"messages\"][-1]\n",
    "    tool_call = last.tool_calls[0]  # guarded by should_continue\n",
    "    sql = tool_call[\"args\"].get(\"query\") or tool_call[\"args\"].get(\"sql\")\n",
    "    llm_with_tools = llm.bind_tools([run_query_tool], tool_choice=\"any\")\n",
    "    response = llm_with_tools.invoke(\n",
    "        [SystemMessage(content=check_query_system_prompt), HumanMessage(content=sql)]\n",
    "    )\n",
    "    # Keep the same id so the tool response threads correctly\n",
    "    response.id = last.id\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# --- Node: summarize + trim history ---\n",
    "def summarize_conversation(state: State):\n",
    "    prior = state.get(\"summary\", \"\")\n",
    "    prompt = (\n",
    "        f\"This is summary of the conversation to date: {prior}\\n\\n\"\n",
    "        \"Extend the summary by taking into account the new messages above:\"\n",
    "        if prior\n",
    "        else \"Create a summary of the conversation above:\"\n",
    "    )\n",
    "    msgs = [*state[\"messages\"], HumanMessage(content=prompt)]\n",
    "    response = llm.invoke(msgs)\n",
    "\n",
    "    # keep only last 2 messages\n",
    "    to_delete = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": to_delete}\n",
    "\n",
    "# --- Routing ---\n",
    "def should_continue(state: State) -> Literal[\"check_query\", \"summarize_conversation\"]:\n",
    "    last = state[\"messages\"][-1]\n",
    "    return \"check_query\" if getattr(last, \"tool_calls\", None) else \"summarize_conversation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6ad0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Build graph =====\n",
    "def get_builder():\n",
    "    builder = StateGraph(State)\n",
    "\n",
    "    builder.add_node(\"prep_list_tables\", prep_list_tables)\n",
    "    builder.add_node(\"list_tables\", list_tables_node)\n",
    "    builder.add_node(\"show_tables\", show_tables)\n",
    "\n",
    "    builder.add_node(\"call_get_schema\", call_get_schema)\n",
    "    builder.add_node(\"get_schema\", get_schema_node)\n",
    "\n",
    "    builder.add_node(\"generate_query\", generate_query)\n",
    "    builder.add_node(\"check_query\", check_query)\n",
    "    builder.add_node(\"run_query\", run_query_node)\n",
    "\n",
    "    builder.add_node(\"summarize_conversation\", summarize_conversation)\n",
    "\n",
    "    builder.add_edge(START, \"prep_list_tables\")\n",
    "    builder.add_edge(\"prep_list_tables\", \"list_tables\")\n",
    "    builder.add_edge(\"list_tables\", \"show_tables\")\n",
    "    builder.add_edge(\"show_tables\", \"call_get_schema\")\n",
    "    builder.add_edge(\"call_get_schema\", \"get_schema\")\n",
    "    builder.add_edge(\"get_schema\", \"generate_query\")\n",
    "\n",
    "    builder.add_conditional_edges(\"generate_query\", should_continue)\n",
    "    builder.add_edge(\"check_query\", \"run_query\")\n",
    "    builder.add_edge(\"run_query\", \"generate_query\")\n",
    "    builder.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "    return builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2cda0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The available tracks to students are data science and data analysis.\n"
     ]
    }
   ],
   "source": [
    "with PostgresSaver.from_conn_string(db_uri) as checkpointer:\n",
    "    checkpointer.setup()  # idempotent\n",
    "    builder = get_builder()\n",
    "    graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "    config = {\"configurable\": {\n",
    "        \"thread_id\": \"5\",\n",
    "        \"checkpoint_ns\": \"\",\n",
    "    }}\n",
    "\n",
    "    input_message = HumanMessage(content=\"What tracks are available to students?\")\n",
    "    output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "\n",
    "\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ed-eng-c4-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
